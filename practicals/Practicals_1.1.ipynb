{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a44e75",
   "metadata": {},
   "source": [
    "# Practicals for lecture 1.1\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vigji/python-cimec-2025/blob/main/practicals/Practicals_1.1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a4f38",
   "metadata": {},
   "source": [
    "## More on `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c34053",
   "metadata": {},
   "source": [
    "#### 1.1.0 Operations with arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c18b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3540255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array with a range of numbers from 1 to 10 (not from 0 to 9!), \n",
    "# then elevate each element to the power of 2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "828fd104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.stack to create a 10*10 matrix with rows of identical values going from 0 to 9, in this way:\n",
    "\n",
    "# final_matrix = [[0,0,0,0,0,...],\n",
    "#                 [1,1,1,1,1,...],\n",
    "#                 [2,2,2,2,2,...],\n",
    "#                 [.., .., .., ]]\n",
    "\n",
    "# Hint: you can use a list comprehension to create the list of arrays to pass to np.stack()!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05b94baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have the following data matrix:\n",
    "data_matrix = np.array([[1,2,3, 2, 5, 0, 2], \n",
    "                        [4,5,6, 8, 2, 3, 1]])\n",
    "\n",
    "# And this array of offsets, one for every row:\n",
    "offsets = np.array([2, 5])\n",
    "\n",
    "# Use stack to repeat the offsets as many times as the number of columns in data_matrix,\n",
    "# so that you can subtract offsets from each row of data_matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16f90e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_image():\n",
    "    import requests\n",
    "    from io import BytesIO\n",
    "\n",
    "    response = requests.get(\"https://github.com/vigji/python-cimec-2025/raw/main/practicals/data/correct_img.npy\")\n",
    "    \n",
    "    return np.load(BytesIO(response.content))\n",
    "\n",
    "img = fetch_image()\n",
    "\n",
    "# Start from the matrix you downloaded with the fetch_image() function above (same as last week practicals).\n",
    "# Now use np.concatenate to repeat the matrix 2 times vertically, and 3 times horizontally.\n",
    "# Hint: you will have to call np.concatenate twice to do it!\n",
    "# Use plt.matshow() to check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb84d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google (or chatGPT) how to use the np.tile() function to perform the same tiling using only one operation!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ec51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plt.matshow() to show the transposed image:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1808e6",
   "metadata": {},
   "source": [
    "#### 1.1.1 Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fix the offset subtraction above using broadcasting instead of stacking arrays!\n",
    "\n",
    "# you have the following data matrix:\n",
    "data_matrix = np.array([[1,2,3, 2, 5, 0, 2], \n",
    "                        [4,5,6, 8, 2, 3, 1]])\n",
    "\n",
    "# And this array of offsets, one for every row:\n",
    "offsets = np.array([2, 5])\n",
    "\n",
    "# We want to subtract the offsets from each row of data_matrix.\n",
    "\n",
    "# Remember, to match arrays we need to have either matching dimension size, OR a dimension size of 1.\n",
    "# Currently, numpy is comparing second dimension of data_matrix with first dimension of offsets, \n",
    "# and they do not match.\n",
    "\n",
    "# Use the syntax we have seen to add new singleton dimensions to convert offsets to an array\n",
    "# of shape (2, 1), and then use it to try the operation again, so that numpy can broadcast the subtraction:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4caf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D array of shape (2, 3, 4) filled with random numbers between 0 and 1\n",
    "# Create a 1D array of shape (4,) with values [1, 2, 3, 4]\n",
    "# Use broadcasting to multiply each element in the last dimension of the 3D array\n",
    "# by the corresponding value in the 1D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867551a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two arrays:\n",
    "# - A 2D array of shape (3, 4) with random integers between 0 and 9\n",
    "# - A 1D array of shape (4,) with values [2, 4, 6, 8]\n",
    "# Use broadcasting to create a boolean mask where each element in the 2D array\n",
    "# is greater than the corresponding value in the 1D array\n",
    "# Then use this mask to set all elements that are greater to 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d801e0",
   "metadata": {},
   "source": [
    "#### 1.1.2 Stats over numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcb79588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.random.normal to initialize a vector of 1000 numbers of mean 10 and standard deviation 3. \n",
    "# Then calculate the actual mean and standard deviation of the array you got using numpy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28868e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: this function generate sample Reaction Times data\n",
    "# for many subjects. (200 subjects, 1000 RTs each)\n",
    "\n",
    "def generate_RT_data(n_subjects=200, n_samples_per_subject=1000):\n",
    "    \"\"\"\n",
    "    Generates Reaction Time data for a given number of subjects, each with their own distribution parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    n_subjects (int): Number of subjects\n",
    "    n_samples_per_subject (int): Number of samples (RT times) per subject\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: A 2D array where each row represents the RT times for a subject\n",
    "    \"\"\"\n",
    "    np.random.seed(0)  # For reproducibility\n",
    "    shift = 0.500  # Shift of the distribution\n",
    "    # Initialize an empty array to store the RT times for all subjects\n",
    "    RT_data = np.empty((n_subjects, n_samples_per_subject))\n",
    "    \n",
    "    for i in range(n_subjects):\n",
    "        # Assuming mu ranges from 90 to 110 and sigma from 10 to 20 for the subjects\n",
    "        mu = np.random.uniform(0.090, 0.110)\n",
    "        sigma = np.random.uniform(0.10, 0.20)\n",
    "        RT_data[i] = np.random.normal(mu, sigma, n_samples_per_subject) + shift\n",
    "    \n",
    "    return RT_data\n",
    "\n",
    "# This is our data matrix:\n",
    "rt_data = generate_RT_data()\n",
    "# Compute the mean of the RT times for each subject and store it in a reaction_time_means\n",
    "# array. Rember to specify the axis along which you are taking the mean!\n",
    "\n",
    "\n",
    "# Then, use broadcasting to subtract the mean RTs from the data.\n",
    "# Bonus: then organize your code in a function for mean subtraction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc69078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO DOWNLOAD THE DATA\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def download_meteo_data(start_date=\"2022-01-01\", end_date=\"2022-12-31\",\n",
    "                        latitude=\"45.88204\", longitude=\"11.03647\",\n",
    "                        data=\"temperature_2m\"):\n",
    "    \"\"\"Download meteo historical data from open-meteo.com.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        start_date : str\n",
    "            Beginning of time series.\n",
    "            \n",
    "        end_date : str\n",
    "            End of time series.\n",
    "            \n",
    "        latitude : float\n",
    "            Latitude of the time series.\n",
    "            \n",
    "        longitude : float\n",
    "            Longitude of the time series.\n",
    "            \n",
    "        data : str\n",
    "            Data to download. One of \"temperature_2m\", \"relativehumidity_2m\",\n",
    "            \"precipitation\", \"snowfall\", \"windspeed_10m\".\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "        np.array\n",
    "            1D array of timestamps\n",
    "        np.array\n",
    "            1D array of data, sampled every hour (24 points per day)\n",
    "\n",
    "    \"\"\"\n",
    "    BASE_URL = \"https://archive-api.open-meteo.com/v1/\"\n",
    "    query = f\"archive?latitude={latitude}&longitude={longitude}&start_date={start_date}&end_date={end_date}&hourly={data}\"\n",
    "\n",
    "    r = requests.get(BASE_URL + query)\n",
    "    json_dict = json.loads(r.text)\n",
    "    \n",
    "    if \"hourly\" not in json_dict.keys():\n",
    "        print(json_dict)\n",
    "        return None, None\n",
    "    else:\n",
    "        return np.array(json_dict[\"hourly\"][\"time\"]).reshape(-1, 24), np.array(json_dict[\"hourly\"][data]).reshape(-1, 24)\n",
    "\n",
    "timestamps_array, temperatures_array = download_meteo_data()\n",
    "temperatures_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a083371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell above to download an array of temperatures in Rovereto during 2022. \n",
    "# Temperatures data are sampled every hour: can you interpret the shape of the array?\n",
    "\n",
    "# Plot it with plt.matshow() to check if it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plt.plot to show temperatures for all days (each day a line). You can do it in a for loop,\n",
    "# or in one call of the function given the right dimension order for the data matrix!\n",
    "\n",
    "# Compute the average temperature line over days, and plot it on top of the individual day lines.\n",
    "# (you can pass the `c` argument to specify line color. \n",
    "# Make the lines of the individual days gray and the average red!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da3dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the temperatures data, create one-dimensional arrays with the minimum, mean and maximum temperatures\n",
    "# of each day.\n",
    "\n",
    "\n",
    "# Look into the documentation for the plt.fill_between() function, and use it to make a plot \n",
    "# where you represent the temperature range for every day of the year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same, but now representing the 25th-75th percentile range for every day.\n",
    "\n",
    "\n",
    "# Look into the documentation for the plt.fill_between() function, and use it to make a plot \n",
    "# where you represent the temperature range for every day of the year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc752441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Advanced]\n",
    "# To do this exercise, you'll have to know or look into how to reshape arrays.\n",
    "#  Are Murphy's laws true? Does it rain more on weekends?\n",
    "\n",
    "# 0. Look into docs of download_meteo_data(), and use it to download *precipitation data* from 2022, \n",
    "# but change the end_date argument to be end_date=\"2022-12-30\" to have a multiple of 7 days!\n",
    "\n",
    "# 1. Compute daily averages of precipitation (you will get a 1D array of shape (n_days,))\n",
    "# 2. Reshape the daily averages array to be of shape (n_weeks, n_weekdays=7)\n",
    "# 3. Take the average over the n_weeks dimension and plot median precipitation for each weekday!\n",
    "# 4. Plot the average (bonus: fill in using std, or percentiles - in which case replace mean with median)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64925e6",
   "metadata": {},
   "source": [
    "#### 1.1.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64394a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to the RT data. Assume that w consider outliers the RTs longer than 0.7 seconds. \n",
    "# Compute again the mean RTs after having excluded such outliers, but make sure you use only vector operations!\n",
    "\n",
    "# (Hint: an easy way to exclude outliers without using loops is by setting nans in the matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e996ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the subject with the shortest trial reaction time of the whole dataset \n",
    "# (not shortest average!)\n",
    "# (Hint: you will need two operations...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286981cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use argmax to find the index of the warmest hour in the (non-reshaped) temperature_array.\n",
    "# Then, use the index over timestamps_array to read out the corresponding timestamp.\n",
    "timestamps_array, temperatures_array = download_meteo_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Bonus: we did not do this in class!)\n",
    "# We can use the np.argsort() function to produce the indexes array required to\n",
    "# order an array in ascending or descending values.\n",
    "\n",
    "# For example:\n",
    "random_arr = np.array([0.1, 5, 3.4, 2.3])\n",
    "ordering_idxs = np.argsort(random_arr)\n",
    "random_arr[ordering_idxs]  # with this index, this is now ordered!\n",
    "\n",
    "# Let's make a ranking of the 5 warmest hours of 2022! \n",
    "# Sort the (non-reshaped) temperature array using the indexes produced by np.argsort.\n",
    "# so that the first elements are the highest temperatures.\n",
    "# Then sort the imestamps array with the same indexes, and take the first 5.\n",
    "#\n",
    "# Double check you match the result that you have got in the exercises above!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
