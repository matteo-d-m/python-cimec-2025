{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a44e75",
   "metadata": {},
   "source": [
    "# Practicals for lecture 1.1\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vigji/python-cimec-2025/blob/main/practicals/Practicals_1.1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a4f38",
   "metadata": {},
   "source": [
    "## More on `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c34053",
   "metadata": {},
   "source": [
    "#### 1.1.0 Operations with arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c18b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3540255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array with a range of numbers from 1 to 10 (not from 0 to 9!), \n",
    "# then elevate each element to the power of 2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "828fd104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.stack to create a 10*10 matrix with rows of identical values going from 0 to 9, in this way:\n",
    "\n",
    "# final_matrix = [[0,0,0,0,0,...],\n",
    "#                 [1,1,1,1,1,...],\n",
    "#                 [2,2,2,2,2,...],\n",
    "#                 [.., .., .., ]]\n",
    "\n",
    "# Hint: you can use a list comprehension to create the list of arrays to pass to np.stack()!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05b94baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have the following data matrix:\n",
    "data_matrix = np.array([[1,2,3, 2, 5, 0, 2], \n",
    "                        [4,5,6, 8, 2, 3, 1]])\n",
    "\n",
    "# And this array of offsets, one for every row:\n",
    "offsets = np.array([2, 5])\n",
    "\n",
    "# Use stack to repeat the offsets as many times as the number of columns in data_matrix,\n",
    "# so that you can subtract offsets from each row of data_matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16f90e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_image():\n",
    "    import requests\n",
    "    from io import BytesIO\n",
    "\n",
    "    response = requests.get(\"https://github.com/vigji/python-cimec-2025/raw/main/practicals/data/correct_img.npy\")\n",
    "    \n",
    "    return np.load(BytesIO(response.content))\n",
    "\n",
    "img = fetch_image()\n",
    "\n",
    "# Start from the matrix you downloaded with the fetch_image() function above (same as last week practicals).\n",
    "# Now use np.concatenate to repeat the matrix 2 times vertically, and 3 times horizontally.\n",
    "# Hint: you will have to call np.concatenate twice to do it!\n",
    "# Use plt.matshow() to check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb84d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google (or chatGPT) how to use the np.tile() function to perform the same tiling using only one operation!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ec51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plt.matshow() to show the transposed image:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1808e6",
   "metadata": {},
   "source": [
    "#### 1.1.1 Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fix the offset subtraction above using broadcasting instead of stacking arrays!\n",
    "\n",
    "# you have the following data matrix:\n",
    "data_matrix = np.array([[1,2,3, 2, 5, 0, 2], \n",
    "                        [4,5,6, 8, 2, 3, 1]])\n",
    "\n",
    "# And this array of offsets, one for every row:\n",
    "offsets = np.array([2, 5])\n",
    "\n",
    "# We want to subtract the offsets from each row of data_matrix.\n",
    "\n",
    "# Remember, to match arrays we need to have either matching dimension size, OR a dimension size of 1.\n",
    "# Currently, numpy is comparing second dimension of data_matrix with first dimension of offsets, \n",
    "# and they do not match.\n",
    "\n",
    "# Use the syntax we have seen to add new singleton dimensions to convert offsets to an array\n",
    "# of shape (2, 1), and then use it to try the operation again, so that numpy can broadcast the subtraction:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4caf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D array of shape (2, 3, 4) filled with random numbers between 0 and 1\n",
    "# Create a 1D array of shape (4,) with values [1, 2, 3, 4]\n",
    "# Use broadcasting to multiply each element in the last dimension of the 3D array\n",
    "# by the corresponding value in the 1D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867551a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two arrays:\n",
    "# - A 2D array of shape (3, 4) with random integers between 0 and 9\n",
    "# - A 1D array of shape (4,) with values [2, 4, 6, 8]\n",
    "# Use broadcasting to create a boolean mask where each element in the 2D array\n",
    "# is greater than the corresponding value in the 1D array\n",
    "# Then use this mask to set all elements that are greater to 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d801e0",
   "metadata": {},
   "source": [
    "#### 1.1.2 Stats over numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcb79588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.random.normal to initialize a vector of 1000 numbers of mean 10 and standard deviation 3. \n",
    "# Then calculate the actual mean and standard deviation of the array you got using numpy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28868e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: this function generate sample Reaction Times data\n",
    "# for many subjects. (200 subjects, 1000 RTs each)\n",
    "\n",
    "def generate_RT_data(n_subjects=200, n_samples_per_subject=1000):\n",
    "    \"\"\"\n",
    "    Generates Reaction Time data for a given number of subjects, each with their own distribution parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    n_subjects (int): Number of subjects\n",
    "    n_samples_per_subject (int): Number of samples (RT times) per subject\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: A 2D array where each row represents the RT times for a subject\n",
    "    \"\"\"\n",
    "    np.random.seed(0)  # For reproducibility\n",
    "    shift = 0.500  # Shift of the distribution\n",
    "    # Initialize an empty array to store the RT times for all subjects\n",
    "    RT_data = np.empty((n_subjects, n_samples_per_subject))\n",
    "    \n",
    "    for i in range(n_subjects):\n",
    "        # Assuming mu ranges from 90 to 110 and sigma from 10 to 20 for the subjects\n",
    "        mu = np.random.uniform(0.090, 0.110)\n",
    "        sigma = np.random.uniform(0.10, 0.20)\n",
    "        RT_data[i] = np.random.normal(mu, sigma, n_samples_per_subject) + shift\n",
    "    \n",
    "    return RT_data\n",
    "\n",
    "# This is our data matrix:\n",
    "rt_data = generate_RT_data()\n",
    "# Compute the mean of the RT times for each subject and store it in a reaction_time_means\n",
    "# array. Rember to specify the axis along which you are taking the mean!\n",
    "\n",
    "\n",
    "# Then, use broadcasting to subtract the mean RTs from the data.\n",
    "# Bonus: then organize your code in a function for mean subtraction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc69078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f94a4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.4, 2.9, 3.2, ..., 9.1, 9.3, 8.6])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS CELL TO DOWNLOAD THE DATA\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def download_meteo_data(start_date=\"2022-01-01\", end_date=\"2022-12-31\",\n",
    "                        latitude=\"45.88204\", longitude=\"11.03647\",\n",
    "                        data=\"temperature_2m\"):\n",
    "    \"\"\"Download meteo historical data from open-meteo.com.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        start_date : str\n",
    "            Beginning of time series.\n",
    "            \n",
    "        end_date : str\n",
    "            End of time series.\n",
    "            \n",
    "        latitude : float\n",
    "            Latitude of the time series.\n",
    "            \n",
    "        longitude : float\n",
    "            Longitude of the time series.\n",
    "            \n",
    "        data : str\n",
    "            Data to download. One of \"temperature_2m\", \"relativehumidity_2m\",\n",
    "            \"precipitation\", \"snowfall\", \"windspeed_10m\".\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "        np.array\n",
    "            1D array of timestamps\n",
    "        np.array\n",
    "            1D array of data, sampled every hour (24 points per day)\n",
    "\n",
    "    \"\"\"\n",
    "    BASE_URL = \"https://archive-api.open-meteo.com/v1/\"\n",
    "    query = f\"archive?latitude={latitude}&longitude={longitude}&start_date={start_date}&end_date={end_date}&hourly={data}\"\n",
    "\n",
    "    r = requests.get(BASE_URL + query)\n",
    "    json_dict = json.loads(r.text)\n",
    "    \n",
    "    if \"hourly\" not in json_dict.keys():\n",
    "        print(json_dict)\n",
    "        return None, None\n",
    "    else:\n",
    "        return (np.array(json_dict[\"hourly\"][k]) for k in [\"time\", data])\n",
    "\n",
    "\n",
    "timestamps_array, temperatures_array = download_meteo_data()\n",
    "temperatures_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a083371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell above to download an array of temperatures in Rovereto during 2022. \n",
    "# Temperatures data are sampled every hour, so the array has the length of num_days_year * num_hours_day\n",
    "\n",
    "# Reshape the array to be a matrix of shape (n_days, n_hours). \n",
    "n_days = 365\n",
    "n_hours = 24\n",
    "\n",
    "# Plot it with plt.matshow() to check if it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plt.plot to show temperatures for all days (each day a line). You can do it in a for loop,\n",
    "# or in one call of the function given the right dimension order for the data matrix!\n",
    "\n",
    "# Compute the average temperature line over days, and plot it on top of the individual day lines.\n",
    "# (you can pass the `c` argument to specify line color. \n",
    "# Make the lines of the individual days gray and the average red!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da3dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the temperatures data, create one-dimensional arrays with the minimum, mean and maximum temperatures\n",
    "# of each day.\n",
    "\n",
    "\n",
    "# Look into the documentation for the plt.fill_between() function, and use it to make a plot \n",
    "# where you represent the temperature range for every day of the year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same, but now representing the 25th-75th percentile range for every day.\n",
    "\n",
    "\n",
    "# Look into the documentation for the plt.fill_between() function, and use it to make a plot \n",
    "# where you represent the temperature range for every day of the year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc752441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are Murphy's laws true? Does it rain more on weekends?\n",
    "\n",
    "# Look into docs of download_meteo_data(), and use it to download *precipitation data* from 2022, \n",
    "# but change the end_date argument to be end_date=\"2022-12-30\" to have a multiple of 7 days!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, reshape the daily averages array to be of shape (n_weeks, n_weekdays)\n",
    "\n",
    "\n",
    "# Finally, take the average over the n_weeks dimension and plot median precipitation for each weekday!\n",
    "# Bonus points: represent the dispersion of the data (std or percentiles) using plt.fill_between().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64925e6",
   "metadata": {},
   "source": [
    "#### 1.1.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a64394a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81115773, 0.86475827, 0.77084648, 0.74749284, 0.8093885 ,\n",
       "       0.72805993, 0.79298497, 0.79834661, 0.8063856 , 0.73985924,\n",
       "       0.80264745, 0.84754963, 0.78776014, 0.77088147, 0.80802886,\n",
       "       0.85612545, 0.81509353, 0.73642611, 0.82075299, 0.82811378,\n",
       "       0.81536649, 0.75005669, 0.75521574, 0.84153778, 0.78390486,\n",
       "       0.78420967, 0.74399619, 0.72675275, 0.83439989, 0.82156992,\n",
       "       0.7974965 , 0.77913795, 0.75997075, 0.76608587, 0.72580777,\n",
       "       0.80269684, 0.83290023, 0.83548828, 0.8413841 , 0.73372243,\n",
       "       0.72861656, 0.80981105, 0.79096449, 0.83197026, 0.7866519 ,\n",
       "       0.81647495, 0.73861152, 0.8409581 , 0.78271327, 0.79435368,\n",
       "       0.76762708, 0.78778964, 0.83811019, 0.86749636, 0.74426569,\n",
       "       0.7526576 , 0.734203  , 0.79632558, 0.82286621, 0.75289716,\n",
       "       0.76976085, 0.75365782, 0.73455426, 0.76607152, 0.8181038 ,\n",
       "       0.75064712, 0.79173779, 0.73611937, 0.8396602 , 0.72361491,\n",
       "       0.79163198, 0.85761754, 0.78561538, 0.77479955, 0.86016693,\n",
       "       0.74060624, 0.8574357 , 0.84045955, 0.81376435, 0.74630823,\n",
       "       0.84252246, 0.74570625, 0.74416394, 0.79137816, 0.74118812,\n",
       "       0.77754565, 0.83013921, 0.74651739, 0.79596783, 0.81994178,\n",
       "       0.77345507, 0.75005589, 0.79397457, 0.76944242, 0.84424135,\n",
       "       0.8501151 , 0.78247542, 0.74321952, 0.79307677, 0.75998962,\n",
       "       0.79837664, 0.76414117, 0.80362874, 0.8228558 , 0.74026802,\n",
       "       0.85537469, 0.72177344, 0.85277324, 0.77129401, 0.78910206,\n",
       "       0.85364162, 0.80671244, 0.72766146, 0.84629037, 0.71792916,\n",
       "       0.82478739, 0.76247497, 0.81552076, 0.84342648, 0.72946355,\n",
       "       0.76200688, 0.80716209, 0.83618964, 0.80492079, 0.7569801 ,\n",
       "       0.8112835 , 0.8092546 , 0.7630885 , 0.78652704, 0.81225491,\n",
       "       0.81572751, 0.767207  , 0.86669523, 0.73838438, 0.81019667,\n",
       "       0.78291984, 0.75739552, 0.84337741, 0.81632398, 0.78432948,\n",
       "       0.7980914 , 0.77468902, 0.74101716, 0.7568266 , 0.81509783,\n",
       "       0.8095944 , 0.77439459, 0.78240514, 0.86484604, 0.78561607,\n",
       "       0.7699119 , 0.77129519, 0.79802541, 0.84963202, 0.81132397,\n",
       "       0.74930011, 0.76960637, 0.79052209, 0.79547554, 0.75115206,\n",
       "       0.83909441, 0.76254249, 0.73048761, 0.766067  , 0.85983555,\n",
       "       0.78149374, 0.83009566, 0.8315766 , 0.79060701, 0.80749135,\n",
       "       0.85033541, 0.76223031, 0.82703758, 0.73058929, 0.79042688,\n",
       "       0.85459688, 0.75012959, 0.78190506, 0.79255518, 0.81920556,\n",
       "       0.83497959, 0.77837469, 0.79419619, 0.81621262, 0.75995419,\n",
       "       0.8583809 , 0.79187285, 0.81521875, 0.74133967, 0.78409243,\n",
       "       0.74541749, 0.83334374, 0.81986686, 0.86774777, 0.78501924,\n",
       "       0.78816531, 0.78737571, 0.75698121, 0.7193546 , 0.76670422])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go back to the RT data. Assume that w consider outliers the RTs longer than 0.7 seconds. \n",
    "# Compute again the mean RTs after having excluded such outliers, but make sure you use only vector operations!\n",
    "\n",
    "# (Hint: an easy way to exclude outliers without using loops is by setting nans in the matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e996ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the subject with the shortest trial reaction time of the whole dataset \n",
    "# (not shortest average!)\n",
    "# (Hint: you will need two operations...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286981cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use argmax to find the index of the warmest hour in the (non-reshaped) temperature_array.\n",
    "# Then, use the index over timestamps_array to read out the corresponding timestamp.\n",
    "timestamps_array, temperatures_array = download_meteo_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Bonus: we did not do this in class!)\n",
    "# We can use the np.argsort() function to produce the indexes array required to\n",
    "# order an array in ascending or descending values.\n",
    "\n",
    "# For example:\n",
    "random_arr = np.array([0.1, 5, 3.4, 2.3])\n",
    "ordering_idxs = np.argsort(random_arr)\n",
    "random_arr[ordering_idxs]  # with this index, this is now ordered!\n",
    "\n",
    "# Let's make a ranking of the 5 warmest hours of 2022! \n",
    "# Sort the (non-reshaped) temperature array using the indexes produced by np.argsort.\n",
    "# so that the first elements are the highest temperatures.\n",
    "# Then sort the imestamps array with the same indexes, and take the first 5.\n",
    "#\n",
    "# Double check you match the result that you have got in the exercises above!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
