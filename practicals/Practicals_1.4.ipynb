{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67e435b2",
   "metadata": {},
   "source": [
    "# Practicals for lecture 1.4\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vigji/python-cimec-2025/blob/main/practicals/Practicals_1.4.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7707a684",
   "metadata": {},
   "source": [
    "#### 1.4.0 Organize a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2f3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Let's have a look into how to organize data in a dataframe.\n",
    "\n",
    "# Use the following function that generates results for many subjects on\n",
    "# an experiment with experimental trials of different difficulty levels.\n",
    "\n",
    "def get_experiment_block_data(n_subjects=50, difficulty_levels=(1, 2, 3, 4, 5), n_repetitions=50):\n",
    "    \"\"\"Generate a dataframe with results from an experiment with experimental blocks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_reps : int\n",
    "        Number of experimental blocks.\n",
    "    n_subjects : int\n",
    "        Number of subjects.\n",
    "    difficulty_levels : tuple\n",
    "        Difficulty levels of the experimental blocks.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with the results of the experiment for each subject.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(42)\n",
    "    subject_dict = dict()\n",
    "    for subject in range(n_subjects):\n",
    "        subject_ability = np.random.randint(1, 6)\n",
    "        difficulty_level_arr = np.random.choice(difficulty_levels, size=n_repetitions)\n",
    "        rt = np.random.normal(1000, 100, size=n_repetitions) * difficulty_level_arr / subject_ability\n",
    "        error = np.random.uniform(0, 1000*difficulty_level_arr / subject_ability, size=n_repetitions)\n",
    "\n",
    "        subject_dict[f\"subject_{subject}\"] = dict(\n",
    "            difficulty_level=difficulty_level_arr,\n",
    "            rt=rt,\n",
    "            error=error,\n",
    "        )\n",
    "\n",
    "    return subject_dict\n",
    "\n",
    "\n",
    "# Run the function to generate the data dictionary.\n",
    "data = get_experiment_block_data()\n",
    "\n",
    "#Â Data is a dictionary with an entry for every subject. Have a look!\n",
    "# Each entry is itself a list, with the trial by trial data\n",
    "# on task difficulty, rection times, and trial error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4455c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this nested data to a (flat) dataframe containing all data.\n",
    "# (Hint: you can create a DataFrame for every subject and then concatenate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c01fd768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the data for subject 0, and create a scatter plot \n",
    "# with the reaction time as a function of the trial difficulty level\n",
    "# (Hint: remember the dataframe.plot() function from last lecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77864f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the subjects dataframe from the csv file at the url:\n",
    "# https://raw.githubusercontent.com/vigji/python-cimec/main/practicals/data/subjects_df.csv\n",
    "\n",
    "subject_df = pd.read_csv(\"https://raw.githubusercontent.com/vigji/python-cimec/main/practicals/data/subjects_df.csv\",\n",
    "                         index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a1d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use boolean indexing on the subject dataframe to include only left-handed males \n",
    "# above 30 years in the analysis.\n",
    "# Plot the reaction time as a function of the trial difficulty \n",
    "# level for this subpopulation only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aed3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Advanced]\n",
    "# The Allen Brain Observatory dataset (https://allensdk.readthedocs.io/en/latest/visual_coding_neuropixels.html)\n",
    "# contains electrophysiology data (single neuron activity) from hundreds of\n",
    "# recording sessions in the visual cortex of mice.\n",
    "\n",
    "# Here you find some of their data:\n",
    "\n",
    "# - a neuron_csv with information about individual neurons from all electrodes from all sessions\n",
    "#   Each neuron has a channel_id column that specifies which electrode it was recorded from\n",
    "#   link: https://github.com/vigji/python-cimec-2024/raw/main/practicals/data/allen_neurons.csv\n",
    "\n",
    "# - A channel_csv with information about individual electrodes from all sessions.\n",
    "#   Each channel has a session_id that specifies from which session it was recorded\n",
    "#   and a ecephys_structure_acronym column with the acronym of the brain area\n",
    "#   where the electrode was:\n",
    "#   link: https://github.com/vigji/python-cimec-2024/raw/main/practicals/data/allen_channels.csv\n",
    "\n",
    "# - A session_csv with information about all sessions and the animal that was recorded \n",
    "#   in that session.\n",
    "#   link: https://github.com/vigji/python-cimec-2024/raw/main/practicals/data/allen_sessions.csv \n",
    "\n",
    "# Use the read_csv function to read data from the links!\n",
    "import pandas as pd\n",
    "root_url_string = \"https://github.com/vigji/python-cimec-2024/raw/main/practicals/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc50af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only neurons that were recorded in animals of wild type genotype (wt/wt)\n",
    "# and have a valid entry in the g_dsi_dg (their direction selectivity index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e3124",
   "metadata": {},
   "source": [
    "#### 1.4.1  `.groupby()` and index broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12fcc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T07:35:32.752413Z",
     "start_time": "2023-05-22T07:35:32.296106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>winddirection_10m</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-01 00:00:00</td>\n",
       "      <td>6.1</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-01 02:00:00</td>\n",
       "      <td>5.2</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-01 03:00:00</td>\n",
       "      <td>5.4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-01 04:00:00</td>\n",
       "      <td>5.1</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2025-04-20 21:00:00</td>\n",
       "      <td>15.5</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>2025-04-20 22:00:00</td>\n",
       "      <td>14.8</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>97.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>2025-04-20 23:00:00</td>\n",
       "      <td>14.3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows Ã 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time  temperature_2m  relative_humidity_2m  precipitation  \\\n",
       "0   2025-04-01 00:00:00             6.1                  82.0            0.0   \n",
       "1                   NaT             NaN                   NaN            NaN   \n",
       "2   2025-04-01 02:00:00             5.2                  84.0            0.0   \n",
       "3   2025-04-01 03:00:00             5.4                  85.0            0.0   \n",
       "4   2025-04-01 04:00:00             5.1                  86.0            0.0   \n",
       "..                  ...             ...                   ...            ...   \n",
       "475                 NaT             NaN                   NaN            NaN   \n",
       "476                 NaT             NaN                   NaN            NaN   \n",
       "477 2025-04-20 21:00:00            15.5                  74.0            0.0   \n",
       "478 2025-04-20 22:00:00            14.8                  75.0            0.0   \n",
       "479 2025-04-20 23:00:00            14.3                  75.0            0.0   \n",
       "\n",
       "     wind_speed_10m  winddirection_10m  hour  dayofyear  \n",
       "0               9.7                4.0   0.0       91.0  \n",
       "1               NaN                NaN   NaN        NaN  \n",
       "2               8.4               20.0   2.0       91.0  \n",
       "3               8.3               18.0   3.0       91.0  \n",
       "4               8.2               15.0   4.0       91.0  \n",
       "..              ...                ...   ...        ...  \n",
       "475             NaN                NaN   NaN        NaN  \n",
       "476             NaN                NaN   NaN        NaN  \n",
       "477             3.2               90.0  21.0      110.0  \n",
       "478             2.9               97.0  22.0      110.0  \n",
       "479             3.1              126.0  23.0      110.0  \n",
       "\n",
       "[480 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the meteo dataset using the function below\n",
    "import numpy as np\n",
    "\n",
    "def get_meteo_dataset():\n",
    "    \"\"\"Get a meteo dataset from the open-meteo API using a fixed window.\n",
    "    Note how easy it is to get data from the web with pandas! As long as we give the URL of the csv data, pandas can read it.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    # URL = \"https://api.open-meteo.com/v1/forecast?latitude=52.52&longitude=13.41&current=temperature_2m,relativehumidity_2m,precipitation,windspeed_10m,winddirection_10m&start_date=2023-02-10&end_date=2023-05-28&format=csv\"\n",
    "    URL = \"https://api.open-meteo.com/v1/forecast?latitude=52.52&longitude=13.41&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,precipitation,wind_speed_10m,winddirection_10m&start_date=2025-04-01&end_date=2025-04-20&format=csv\"\n",
    "    df = pd.read_csv(URL, skiprows=6)  # read the csv file, skipping the first 3 rows (a header)\n",
    "    df.columns = [col.split(\" \")[0] for col in df.columns]  # simplify column names\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])  # convert the time column to datetime\n",
    "    df[\"hour\"], df[\"dayofyear\"] = df[\"time\"].dt.hour, df[\"time\"].dt.dayofyear  # extract the hour and day of year\n",
    "\n",
    "    # Here we artificially corrupt some of the data:\n",
    "    missing_idx = np.random.choice(df.index[:1000], 100)\n",
    "    df.loc[missing_idx, :] = np.nan\n",
    "    return df\n",
    "\n",
    "# This new meteo dataset has columns for the day of the year, \n",
    "# hour of the day, and day of the week.\n",
    "# Check out the data and make sure we don't have missing values!\n",
    "df = get_meteo_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6eebe25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T07:35:39.971697Z",
     "start_time": "2023-05-22T07:35:39.961574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the .groupby() method to compute the mean temperature for each hour of the day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b981630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas index broadcasting, subtract from each day of the year \n",
    "# its average temperature, and plot the result to check if it makes sense.\n",
    "# (Hint: you will have to set a new index to the dataframe \n",
    "# for the broadcasting to work):\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61ccbd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Advanced]\n",
    "\n",
    "# From the Allen datasets you have loaded above, produce a new dataframe \n",
    "# that for every brain area has a column with the average firing rate\n",
    "# and a column with the average direction selectivity index for that area.\n",
    "\n",
    "# Sort the areas by average DSI; do the first acronyms that you see\n",
    "# make sense? (to find the meanings of the acronyms, you can read the\n",
    "# structures csv file at \n",
    "# https://github.com/vigji/python-cimec-2024/raw/main/practicals/data/allen_structures.csv \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce5072ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Advanced]\n",
    "\n",
    "# Now, let's make a new column \"Z-scored firing rate\" where, for every neuron,\n",
    "# we add the firing rate z-scored within each brain area.\n",
    "# Compute mean and std of firing rate for every area, and compute the Z-score\n",
    "# for every neuron using the mean and std for the brain area it belongs to!\n",
    "# (no for loops of course)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89443646",
   "metadata": {},
   "source": [
    "#### 1.4.2 `.rolling()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4cb9f4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T08:23:06.492706Z",
     "start_time": "2023-05-22T08:23:06.407328Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the maximum and the minimum of the temperature using a rolling window of 24 samples.\n",
    "# Plot the original curve and the smoothed one to check what you did:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0832203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
